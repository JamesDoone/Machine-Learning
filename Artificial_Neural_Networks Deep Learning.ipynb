{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Neuron** is oftern referred to as the **NODE**\n",
    "- Independent variables need to be standardized\n",
    "- To read more about Standardization\n",
    "> http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n",
    "\n",
    "**Output Value**\n",
    "- can be continuous(*price*)\n",
    "- Binary (*will exit yes or no*)\n",
    "- Categorical \n",
    "\n",
    "**Synapses**\n",
    "- assigned weights\n",
    "- By adjustinging the weights, neural systems are able to learn, to determine which signals get passed, etc.\n",
    "\n",
    "**Process of the Neuron**\n",
    "- take the weighted sum of all the input values\n",
    "\n",
    "**The 4 Activation Function**\n",
    "- the Threshhold Function\n",
    "- This is a Yes/No output function\n",
    "\n",
    "- The Sigmoid Function\n",
    "- also a 0 and 1 but provides a probability of y = 1 or 0\n",
    "- Used in Logistic Regression\n",
    "- There are no kinks in the curve like the Activation function--smooth\n",
    "\n",
    "- Rectfier Function\n",
    "- It has a kink but it is very popular\n",
    "- http://jmlr.org/proceedings/papers/v15/glorot11a.pdf\n",
    "\n",
    "- Hyperbolic Tangent Function(tahn)\n",
    "- Simlar to the Sigmoid Function\n",
    "\n",
    "**How Neural Networks**\n",
    "\n",
    "- The Hidden Layer\n",
    "- all independent variables will have synapses connecting them to each node in the Hidden Layer\n",
    "- Each Node redistributes weights on independent variables \n",
    "- For instance, a node may focus on 1) distance to the city and 2) sqft for homes in a given area while marnilizing other variables that are not related to the node's focus.\n",
    "- The neural system takes those 2 independent variables while ignoring the others to create a new more meaningful super variable.\n",
    "\n",
    "**The Cost Function**\n",
    "> C = 1/2(yhat - *y*)^2\n",
    "- What is the error in the prediction\n",
    "- the lower the cost function the closer **yhat** is to **y**\n",
    "- The results of the *cost* function are sent to the *neural* neywork where the model is updated\n",
    "- The goal is to **MINIMIZE THE COST FUNCTION**\n",
    "\n",
    "**Stochastic Gradient Descent**\n",
    "- This will ensure the minimum will be attained if the cost function is not convexed\n",
    "- this method runs one row of independent variables, runs  neural network, then adjust the weights. This process is repeated for entire dataset, one row at a time\n",
    "**Batch Gradient Descent**\n",
    "- The same as the *Stochastic Gradient Descent* except that *all rows of the dataset are run at the same time*\n",
    "**Primary Difference**\n",
    "- *The Stochastic Gradient Descent* focuses on the local minimums whereas a the *the Batch Descent* focuses on the global minimum. **there is a better chance the Stochastic Descent** will find the global minimum. \n",
    "**Back Proprogation** \n",
    "- the return of the errors thru the network which allows the machine to *train* the network **by adjusting the weights**. So each part of the error \n",
    "\n",
    "> Step 1\n",
    "- Randomly initialise the weightsto small numbersclose to 0 (but not 0)\n",
    "\n",
    "> Step 2 \n",
    "- Input the first observation of your dataset in the input layer, each feature in one input node.\n",
    "\n",
    "> Step 3\n",
    "- Forward proprogation from left to right , the neurons are activated in a way that the impact of each neuron's activation is limited by the weights. Proprogate the activations until getting the predicted result y\n",
    "\n",
    "> Step 4\n",
    "- Compare the predicted resultsto the actual result. Measure the generated error.\n",
    "\n",
    "> Step 5 \n",
    "- Back-propogation: from right-to-left, the error is back proprogated.Update the weights according to how much that are responsible for the error. The learning rate decides howmuch we update the weights.\n",
    "\n",
    "> Step 6 \n",
    "- Repeat steps 1 -5 and update the weights after each observation (reinforcement learning). Repeat steps 1 -5 and update the weights after only after a Batch of observations\n",
    "\n",
    "*Independent Variables* that have a greater impact are weighted more than impactful variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\" /Users/jimdoone/Desktop/Machine_Learning__TEMPLATES/Artificial_Neural_Network  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jimdoone/Desktop/Machine_Learning__TEMPLATES/Artificial_Neural_Networks\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/jimdoone/Desktop/Machine_Learning__TEMPLATES/Artificial_Neural_Networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn_Modelling.csv              ann.R\r\n",
      "Stochastic_Gradient_Descent.png  ann.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "5       8  113755.78              2          1               0   \n",
       "6       7       0.00              2          1               1   \n",
       "7       4  115046.74              4          1               0   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0       1       2   3  4        5  6  7  8       9\n",
       "0  619  France  Female  42  2        0  1  1  1  101349\n",
       "1  608   Spain  Female  41  1  83807.9  1  0  1  112543"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_df= pd.DataFrame(X, columns=['CreditScore', 'Geography',\n",
    "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CreditScore Geography  Gender Age Tenure  Balance NumOfProducts HasCrCard  \\\n",
       "0         619    France  Female  42      2        0             1         1   \n",
       "1         608     Spain  Female  41      1  83807.9             1         0   \n",
       "2         502    France  Female  42      8   159661             3         1   \n",
       "3         699    France  Female  39      1        0             2         0   \n",
       "4         850     Spain  Female  43      2   125511             1         1   \n",
       "\n",
       "  IsActiveMember EstimatedSalary  \n",
       "0              1          101349  \n",
       "1              1          112543  \n",
       "2              0          113932  \n",
       "3              0         93826.6  \n",
       "4              1         79084.1  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert countries to dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CreditScore Geography  Gender Age Tenure  Balance NumOfProducts HasCrCard  \\\n",
       "0         619         0  Female  42      2        0             1         1   \n",
       "1         608         2  Female  41      1  83807.9             1         0   \n",
       "\n",
       "  IsActiveMember EstimatedSalary  \n",
       "0              1          101349  \n",
       "1              1          112543  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df= pd.DataFrame(X, columns=['CreditScore', 'Geography',\n",
    "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary'])\n",
    "ref_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert gender to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:,2] = labelencoder_X_2.fit_transform(X[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CreditScore Geography Gender Age Tenure  Balance NumOfProducts HasCrCard  \\\n",
       "0         619         0      0  42      2        0             1         1   \n",
       "1         608         2      0  41      1  83807.9             1         0   \n",
       "\n",
       "  IsActiveMember EstimatedSalary  \n",
       "0              1          101349  \n",
       "1              1          112543  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df= pd.DataFrame(X, columns=['CreditScore', 'Geography',\n",
    "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary'])\n",
    "ref_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avoid multiple dummy variable by using onehotencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features=[1])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>France</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Germany</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   France  Spain  Germany  CreditScore  Gender   Age  Tenure   Balance  \\\n",
       "0     1.0    0.0      0.0        619.0     0.0  42.0     2.0      0.00   \n",
       "1     0.0    0.0      1.0        608.0     0.0  41.0     1.0  83807.86   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0            1.0        1.0             1.0        101348.88  \n",
       "1            1.0        0.0             1.0        112542.58  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df_1= pd.DataFrame(X, columns=['France', 'Spain',\n",
    "       'Germany', 'CreditScore', 'Gender', 'Age', 'Tenure','Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary'])\n",
    "ref_df_1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dummy variable trap\n",
    "- must drop one of the dummy variables. In this scenario, I will drop France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Feature Scaling** is key due to its expensive calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Dense function will randomly initialise the weights to small number close to 0 **(but not 0)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select an Activation Function\n",
    "\n",
    "##### If you dependent variable is binary:\n",
    "\n",
    "- Use either the Threshold Activation Function (between 0 and 1)\n",
    "\n",
    "- Or the sigmoid activation function (returns probaility of y as 1)\n",
    "\n",
    "- See this url for a list of activation funtions: https://www.wikiwand.com/en/Activation_function\n",
    "\n",
    "- the Rectifier function is highly recommended **very popular**\n",
    "\n",
    "- Sigmoid will provide a probablility of each observation\n",
    "- This will enable segmentation of customers\n",
    "\n",
    "\n",
    "\n",
    "> For this example, we will use:\n",
    "- Recitifier for the *Hidden Layers*\n",
    "- Sigmoid function for the *Output Layer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dense function\n",
    "- Output_dim = the number of nodes you want to add in *HIDDEN LAYER* \n",
    "- **Choose the number of nodes in the hidden layer as the average number of nodes in the input layer and the number of nodes in the output layer.**\n",
    "- If you want to be an artist--**Parameter tuning**-- use kfold cross validation. \n",
    "- How are the weights updated?\n",
    "- What is the activation function to be used?\n",
    "- What is the number of nodes\n",
    "# The Add function\n",
    "- does not *add* input-layer into into hidden layer. What it  really does, it adds this hidden layer. And by adding this hidden layer, it is specifiying the number of inputs in the previous layer which is the input layer. The inputs are just the number of nodes of the layer we are adding in the add function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this case, the number of variables in the inner layer is 11\n",
    "# And the number of variable in the outer layer is 1\n",
    "# 11 + 1 / 2 = 6 --> units = 6\n",
    "# The Add function adds the hidden layer \n",
    "classifier.add(Dense(units = 6, kernel_initializer='uniform', activation ='relu', input_dim =11,\n",
    "                     bias_initializer='zeros'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Add a 2nd hidden layer\n",
    "- for a more complex models it might be useful to create a second hidden layer\n",
    "- the 2nd hidden layer, does not need the input_dim argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 6, kernel_initializer='uniform', activation ='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Output Layer\n",
    "- **Need to change units to 1**\n",
    "- Need to replace Activation method \"relu\" to the *SIGMOID ACTIVATION* function\n",
    "- If the *dependent variable* is made up of 3 categories or more, then must change units to the correct number and change the activation to **soft max**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, kernel_initializer='uniform', activation ='sigmoid',\n",
    "                     bias_initializer='zeros'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the optmizer methods **:for the number of optimal weights**\n",
    "- *ADAM* is a stochastic gradient descent algorithm\n",
    "- use 'categorical_crossentropy' if your dependent variable has more than 2 categories\n",
    "- metrics is a criterion to evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 parameters for the fit method\n",
    "- the batch size & the Epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimdoone/anaconda/lib/python3.6/site-packages/keras/models.py:826: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.4949 - acc: 0.7956     \n",
      "Epoch 2/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.4250 - acc: 0.7960     \n",
      "Epoch 3/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.4173 - acc: 0.8235     \n",
      "Epoch 4/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.4117 - acc: 0.8327     \n",
      "Epoch 5/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.4079 - acc: 0.8320     \n",
      "Epoch 6/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.4052 - acc: 0.8345     \n",
      "Epoch 7/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.4036 - acc: 0.8357     \n",
      "Epoch 8/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.4019 - acc: 0.8340     \n",
      "Epoch 9/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.4008 - acc: 0.8357     \n",
      "Epoch 10/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.4001 - acc: 0.8356     \n",
      "Epoch 11/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3997 - acc: 0.8350     \n",
      "Epoch 12/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3990 - acc: 0.8350     \n",
      "Epoch 13/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3984 - acc: 0.8361     \n",
      "Epoch 14/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3982 - acc: 0.8354     \n",
      "Epoch 15/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3981 - acc: 0.8346     \n",
      "Epoch 16/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3975 - acc: 0.8340     \n",
      "Epoch 17/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3970 - acc: 0.8355     \n",
      "Epoch 18/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3972 - acc: 0.8369     \n",
      "Epoch 19/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3966 - acc: 0.8365     \n",
      "Epoch 20/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3970 - acc: 0.8356     \n",
      "Epoch 21/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3966 - acc: 0.8350     \n",
      "Epoch 22/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3969 - acc: 0.8345     \n",
      "Epoch 23/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3960 - acc: 0.8350     \n",
      "Epoch 24/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3966 - acc: 0.8350     \n",
      "Epoch 25/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3963 - acc: 0.8347     \n",
      "Epoch 26/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3962 - acc: 0.8352     \n",
      "Epoch 27/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3960 - acc: 0.8346     \n",
      "Epoch 28/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3961 - acc: 0.8352     \n",
      "Epoch 29/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3958 - acc: 0.8360     \n",
      "Epoch 30/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3959 - acc: 0.8346     \n",
      "Epoch 31/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3959 - acc: 0.8354     \n",
      "Epoch 32/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3955 - acc: 0.8350     \n",
      "Epoch 33/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3952 - acc: 0.8355     \n",
      "Epoch 34/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3951 - acc: 0.8351     \n",
      "Epoch 35/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3951 - acc: 0.8321     \n",
      "Epoch 36/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3953 - acc: 0.8354     \n",
      "Epoch 37/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3950 - acc: 0.8359     \n",
      "Epoch 38/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3948 - acc: 0.8356     \n",
      "Epoch 39/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3944 - acc: 0.8345     \n",
      "Epoch 40/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3943 - acc: 0.8350     \n",
      "Epoch 41/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3943 - acc: 0.8345     \n",
      "Epoch 42/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3944 - acc: 0.8354     \n",
      "Epoch 43/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3943 - acc: 0.8339     \n",
      "Epoch 44/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3942 - acc: 0.8370     \n",
      "Epoch 45/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3940 - acc: 0.8356     \n",
      "Epoch 46/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3942 - acc: 0.8372     \n",
      "Epoch 47/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3944 - acc: 0.8344     \n",
      "Epoch 48/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3948 - acc: 0.8361     \n",
      "Epoch 49/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3934 - acc: 0.8370     \n",
      "Epoch 50/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3943 - acc: 0.8354     \n",
      "Epoch 51/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3935 - acc: 0.8359     \n",
      "Epoch 52/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3941 - acc: 0.8359     \n",
      "Epoch 53/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3938 - acc: 0.8360     \n",
      "Epoch 54/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3943 - acc: 0.8341     \n",
      "Epoch 55/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3933 - acc: 0.8357     \n",
      "Epoch 56/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3942 - acc: 0.8350     \n",
      "Epoch 57/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3938 - acc: 0.8370     \n",
      "Epoch 58/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3940 - acc: 0.8360     \n",
      "Epoch 59/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3940 - acc: 0.8350     \n",
      "Epoch 60/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3942 - acc: 0.8347     \n",
      "Epoch 61/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3937 - acc: 0.8365     \n",
      "Epoch 62/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3936 - acc: 0.8365     \n",
      "Epoch 63/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3930 - acc: 0.8367     \n",
      "Epoch 64/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3937 - acc: 0.8355     \n",
      "Epoch 65/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3936 - acc: 0.8359     \n",
      "Epoch 66/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3940 - acc: 0.8369     \n",
      "Epoch 67/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3936 - acc: 0.8342     \n",
      "Epoch 68/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3936 - acc: 0.8369     \n",
      "Epoch 69/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3927 - acc: 0.8365     \n",
      "Epoch 70/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3935 - acc: 0.8357     \n",
      "Epoch 71/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3938 - acc: 0.8366     \n",
      "Epoch 72/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3932 - acc: 0.8361     \n",
      "Epoch 73/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3936 - acc: 0.8375     \n",
      "Epoch 74/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3936 - acc: 0.8377     \n",
      "Epoch 75/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3938 - acc: 0.8364     \n",
      "Epoch 76/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3934 - acc: 0.8379     \n",
      "Epoch 77/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3937 - acc: 0.8372     \n",
      "Epoch 78/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3935 - acc: 0.8379     \n",
      "Epoch 79/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3928 - acc: 0.8371     \n",
      "Epoch 80/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3938 - acc: 0.8364     \n",
      "Epoch 81/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3929 - acc: 0.8370     \n",
      "Epoch 82/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3934 - acc: 0.8366     \n",
      "Epoch 83/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3929 - acc: 0.8365     \n",
      "Epoch 84/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3929 - acc: 0.8380     \n",
      "Epoch 85/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3927 - acc: 0.8392     \n",
      "Epoch 86/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3926 - acc: 0.8367     \n",
      "Epoch 87/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3921 - acc: 0.8402     \n",
      "Epoch 88/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3924 - acc: 0.8372     \n",
      "Epoch 89/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3922 - acc: 0.8384     \n",
      "Epoch 90/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3922 - acc: 0.8370     \n",
      "Epoch 91/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3918 - acc: 0.8374     \n",
      "Epoch 92/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3917 - acc: 0.8376     \n",
      "Epoch 93/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3916 - acc: 0.8375     \n",
      "Epoch 94/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3912 - acc: 0.8377     \n",
      "Epoch 95/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3912 - acc: 0.8382     \n",
      "Epoch 96/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3905 - acc: 0.8384     \n",
      "Epoch 97/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3893 - acc: 0.8396     \n",
      "Epoch 98/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3878 - acc: 0.8402     \n",
      "Epoch 99/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3867 - acc: 0.8409     \n",
      "Epoch 100/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3845 - acc: 0.8392     \n",
      "Epoch 101/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3816 - acc: 0.8386     \n",
      "Epoch 102/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3787 - acc: 0.8382     \n",
      "Epoch 103/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3755 - acc: 0.8395     \n",
      "Epoch 104/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3719 - acc: 0.8412     \n",
      "Epoch 105/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3679 - acc: 0.8446     \n",
      "Epoch 106/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3646 - acc: 0.8475     \n",
      "Epoch 107/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3624 - acc: 0.8489     \n",
      "Epoch 108/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3603 - acc: 0.8539     \n",
      "Epoch 109/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3580 - acc: 0.8530     \n",
      "Epoch 110/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3551 - acc: 0.8552     \n",
      "Epoch 111/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3543 - acc: 0.8590     \n",
      "Epoch 112/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3532 - acc: 0.8582     \n",
      "Epoch 113/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3517 - acc: 0.8601     \n",
      "Epoch 114/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3516 - acc: 0.8604     \n",
      "Epoch 115/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3503 - acc: 0.8612     \n",
      "Epoch 116/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3505 - acc: 0.8590     \n",
      "Epoch 117/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3494 - acc: 0.8614     \n",
      "Epoch 118/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3499 - acc: 0.8604     \n",
      "Epoch 119/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3483 - acc: 0.8619     \n",
      "Epoch 120/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3481 - acc: 0.8602     \n",
      "Epoch 121/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3480 - acc: 0.8619     \n",
      "Epoch 122/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3471 - acc: 0.8595     \n",
      "Epoch 123/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3483 - acc: 0.8620     \n",
      "Epoch 124/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3469 - acc: 0.8610     \n",
      "Epoch 125/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3470 - acc: 0.8616     \n",
      "Epoch 126/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3468 - acc: 0.8601     \n",
      "Epoch 127/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3466 - acc: 0.8629     \n",
      "Epoch 128/130\n",
      "8000/8000 [==============================] - 3s - loss: 0.3465 - acc: 0.8614     \n",
      "Epoch 129/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3460 - acc: 0.8622     \n",
      "Epoch 130/130\n",
      "8000/8000 [==============================] - 2s - loss: 0.3461 - acc: 0.8617     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123fc4f60>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=10, nb_epoch = 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25730458],\n",
       "       [ 0.38326982],\n",
       "       [ 0.15855235],\n",
       "       ..., \n",
       "       [ 0.238612  ],\n",
       "       [ 0.15958303],\n",
       "       [ 0.18849383]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  False\n",
       "1  False"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  False\n",
       "1  False"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1519,   76],\n",
       "       [ 204,  201]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
